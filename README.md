# Wan2.1-Enhanced 显存分析与视频生成项目

<p align="center">
  <img src="assets/logo.png" alt="Project Logo" width="200"/>
</p>

<p align="center">
  <strong>一个旨在提供强大视频生成能力，并附带深度显存分析与优化工具的项目。</strong>
</p>

---

## 目录

- [1. 项目概览](#1-项目概览)
- [2. 快速开始](#2-快速开始)
- [3. 核心功能与工具使用](#3-核心功能与工具使用)
- [4. 推理配置与性能优化](#4-推理配置与性能优化)
- [5. 测试场景与结果](#5-测试场景与结果)
- [6. 开发者指南](#6-开发者指南)

---

## 1. 项目概览

### 1.1. 项目简介

Wan2.1-Enhanced 是一个先进的视频生成项目，在生成过程中涉及多个大型模型的加载和推理。由于显存使用是关键的性能瓶颈，本项目不仅提供了高质量的视频生成功能，还内置了一套强大的显存分析工具，旨在帮助开发者和用户：

- **精确分析**：详细测量模型在不同配置下的显存使用情况。
- **验证优化**：测试各种显存优化技术（如CPU卸载、注意力切片）的实际效果。
- **指导部署**：为不同硬件环境提供可靠的性能基准和部署建议。

### 1.2. 核心特性

- **多模态视频生成**：支持文生视频、图生视频等多种任务。
- **深度显存分析**：提供精细到每个模型组件和操作步骤的显存追踪能力。
- **自动化分析报告**：一键生成包含关键指标和优化建议的 Markdown 报告。
- **灵活的优化配置**：支持注意力切片、CPU卸载、混合精度等多种优化策略。

### 1.3. 性能亮点

| 优化策略 | 峰值显存 (1.3B模型, 480p) | 性能表现 |
|:---|:---:|:---|
| **基线配置** | ~26.3 GB | 性能最佳，显存占用高 |
| **注意力切片** | (待测试) | 显著降低峰值显存，轻微增加耗时 |
| **CPU模型卸载** | (待测试) | 大幅降低显存占用，推理速度变慢 |

---

## 2. 快速开始

本章节将指导您在最短的时间内完成环境配置，并成功运行一个视频生成示例。

### 2.1. 环境准备

1.  **安装核心依赖**：
    ```bash
    pip install torch torchvision torchaudio
    pip install transformers accelerate
    ```

2.  **准备模型权重**：
    *   请从官方渠道下载 Wan2.1-Enhanced 模型权重。
    *   将下载好的权重文件（通常包含T5、VAE、DiT三个部分）放置在您选择的目录中，例如 `models/`。

### 2.2. 一键运行示例 (文生视频)

使用以下命令，即可快速生成您的第一个视频。请将 `--ckpt_dir` 参数替换为您存放权重的实际路径。

```bash
# 生成一个5秒、480p的视频，并开启基础的显存追踪
python generate.py \
    --task t2v-1.3B \
    --size 832*480 \
    --frame_num 81 \
    --ckpt_dir /path/to/your/models \
    --prompt "A beautiful sunset over the ocean" \
    --precision fp16 \
    --profile_memory true \
    --log_path profiler_logs/quick_start
```

### 2.3. 预期结果

成功运行后，您将在项目根目录下看到生成的视频文件（如 `output.mp4`），并在 `profiler_logs/quick_start/` 目录下找到显存日志文件 `memory_events.json`。

![预期视频输出示例](assets/t2v_res.jpg) 
*（这是一个示例图片，实际输出为视频文件）*

---

## 3. 核心功能与工具使用

### 3.1. 视频生成任务

`generate.py` 脚本是所有生成任务的入口，通过 `--task` 参数控制具体功能。

-   **文生视频 (t2v-1.3B)**: (见快速开始示例)
-   **图生视频 (i2v-14B)**:
    ```bash
    python generate.py \
        --task i2v-14B \
        --image /path/to/input.jpg \
        --ckpt_dir /path/to/your/models \
        ...
    ```

### 3.2. 显存分析工具

我们提供了 `analyze_memory.py` 工具，用于将 `memory_events.json` 日志文件转换为人类可读的分析报告。

**使用方法**

```bash
# 分析快速开始示例中生成的日志
python analyze_memory.py profiler_logs/quick_start/memory_events.json --output reports/quick_start_report.md

# 查看报告
cat reports/quick_start_report.md
```

**报告解读**

生成的报告将包含以下核心内容：

-   **模型加载分析**：T5、VAE、DiT 各组件的显存占用和占比。
-   **峰值显存分析**：整个流程中（包括激活显存）的最高显存点。
-   **生成过程分析**：视频生成每一帧的显存增量变化。
-   **自动化优化建议**：根据分析结果，自动给出高、中、低优先级的优化建议。

---

## 4. 推理配置与性能优化

### 4.1. 关键配置参数

为了方便管理，我们将参数分为基础参数和优化参数。

**基础参数**

-   `--task`: 任务类型 (如 `t2v-1.3B`)。
-   `--ckpt_dir`: 模型权重路径。
-   `--prompt`: 文本提示词。
-   `--size`: 视频分辨率 (如 `832*480`)。
-   `--frame_num`: 视频帧数。

**核心优化参数**

-   `--precision`: 计算精度 (`fp16`, `bf16`, `fp32`)。`fp16` 或 `bf16` 能显著降低显存并加速。
-   `--attention_slicing`: (布尔值) 启用注意力切片，用少量计算时间换取大量峰值显存降低。
-   `--offload_model`: (布尔值) 将不用的模型模块卸载到CPU，极大降低显存，但会增加IO耗时。
-   `--t5_cpu`: (布尔值) 强制将T5模型放在CPU上运行，是显存极度受限时的选择。

### 4.2. 性能优化策略

-   **显存优先**：当你的GPU显存不足时，优先启用 `--attention_slicing`。如果仍然不足，尝试 `--offload_model`。
-   **速度优先**：在显存充足的情况下，关闭所有优化选项 (`--attention_slicing false`, `--offload_model false`) 并使用 `--precision fp16` 以获得最快速度。
-   **均衡选择**：对于大多数现代GPU（如RTX 3090/4090），推荐启用 `--attention_slicing`，它能在几乎不影响体验的情况下，有效防止因峰值显存溢出导致的程序崩溃。

### 4.3. 不同硬件配置建议

| GPU 型号 | 推荐配置 |
|:---|:---|
| **>= 24GB (如 RTX 3090/4090)** | 默认配置或仅开启 `--attention_slicing` |
| **12GB - 24GB (如 RTX 3080)** | 必须开启 `--attention_slicing`，可能需要开启 `--offload_model` |
| **< 12GB** | 必须开启 `--offload_model` 和 `--t5_cpu`，推理会非常慢 |

---

## 5. 测试场景与结果

本节展示了在标准测试场景（1.3B模型生成5秒480p视频）下的性能数据。

### 5.1. 性能对比

| 配置 | 模型总显存 | 峰值激活显存 | 总峰值显存 | 主要发现 |
|:---|:---:|:---:|:---:|:---|
| **基线** | 16.37 GB | 9.9 GB | 26.27 GB | T5编码器是显存瓶颈 (占模型64.6%) |
| **注意力切片** | 16.37 GB | (待测) | (待测) | 预期峰值显存显著下降 |
| **CPU卸载** | (待测) | (待测) | (待测) | 预期总显存大幅降低 |

*注：模型总显存 = T5(10.58GB) + VAE(0.47GB) + DiT(5.31GB)*

### 5.2. 优化建议优先级

1.  **高优先级**：**T5编码器量化**。T5是主要显存消耗者，对其进行INT8量化预计可节省5-6GB显存。
2.  **中优先级**：**激活显存管理**。启用`--attention_slicing`或`--gradient_checkpointing`。
3.  **低优先级**：**DiT模块结构优化**。需要更深入的模型开发工作。

---

## 6. 开发者指南

### 6.1. 技术实现

#### 6.1.1. 模型架构

`WanT2V-1.3B` 模型主要由三个核心组件构成：

-   **文本编码器 (T5)**: 使用 `umt5_xxl` 将文本提示词编码为语义向量。
-   **视频 VAE**: 负责视频帧的编码与解码，在潜在空间中操作以降低维度。
-   **扩散模型 (DiT)**: 一个基于Transformer的扩散模型，在潜在空间中根据文本向量生成视频内容。

#### 6.1.2. 显存监控设计

我们通过在代码的关键节点（如模型加载、推理步骤）插入`torch.cuda.memory_allocated()`和`torch.cuda.max_memory_allocated()`来精确捕获显存变化，并将这些事件记录为结构化的JSON，便于后续自动化分析。

### 6.2. 项目管理

#### 6.2.1. 目录结构

```
Wan2.1-Enhanced/
├── README.md               # 本文档
├── generate.py             # 核心生成脚本
├── analyze_memory.py       # 显存分析工具
├── tests/                  # 测试相关配置文件和脚本
├── profiler_logs/          # 性能分析日志输出目录
├── reports/                # 生成的分析报告目录
└── models/                 # 模型权重存放目录
```

#### 6.2.2. 日志与配置格式

-   **显存日志**：所有显存事件以JSON格式记录在 `profiler_logs/{run_name}/memory_events.json`。
-   **配置文件**：测试配置使用YAML格式，存放于 `tests/configs/`。

---

**文档版本**: v2.2
**最后更新**: 2024年12月
**维护者**: Wan2.1-Enhanced 开发团队
