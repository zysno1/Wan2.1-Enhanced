name: "attention_slicing"
description: "Attention slicing is an optimization technique that reduces the memory footprint of AI inference by breaking down the computationally intensive attention mechanism into sequential, smaller chunks, enabling models to run on hardware with limited VRAM at the cost of slightly slower performance."

model_config:
  task: "t2v-1.3B"
  size: "832*480"
  load_strategy: "block"     # 模型加载策略：full/block
  offload_model: true       # 卸载到CPU
  precision: "fp16"         # 计算精度：fp32/fp16/bf16
  device: "cuda"           # 运行设备
  ckpt_dir: /workspace/Wan2.1-Enhanced/Wan2.1-T2V-1.3B

optimization:
  attention_slicing: true   # 注意力切片
  gradient_checkpointing: false
  batch_size: 1
  micro_batch_size: 1
  parallel_degree: 1       # 模型并行度

logging:
  profile_memory: true
  log_interval: 10         # 记录间隔（步数）
  trace_path: "profiler_logs"